import asyncio
import json

from core.llms.openai_wrapper import openai_llm as llm
# from core.llms.siliconflow_wrapper import sfa_llm
from core.utils.general_utils import is_chinese, extract_and_convert_dates, extract_urls
from loguru import logger
from core.utils.pb_api import PbTalker
import os, re
from datetime import datetime
from urllib.parse import urlparse
import json_repair

from core.utils.general_utils import get_logger


class GeneralAnalysisInfoExtractor:
    def __init__(self, _logger: logger) -> None:
        self.logger = _logger
        self.model = os.environ.get("PRIMARY_MODEL",
                                    "qwen2:7b")  # better to use "Qwen/Qwen2.5-14B-Instruct"
        self.secondary_model = os.environ.get("SECONDARY_MODEL", "THUDM/glm-4-9b-chat")

        self.get_info_prompt = f'''ä½œä¸ºè¯„è®ºåˆ†æåŠ©æ‰‹ï¼Œæˆ‘å°†ä¼šç»™ä½ è§†é¢‘è¥é”€å†…å®¹ä¸‹æ–¹çš„è¯„è®ºæ•°æ®ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šçš„å¤šæ¡è¯„è®ºæ–‡æœ¬ä¸­æå–ä»¥ä¸‹ä¿¡æ¯ï¼š
1. æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢ã€è´Ÿé¢ã€ä¸­æ€§ï¼‰
2. ä¸»è¦ä¸»é¢˜
3. å…³é”®è¯
4. å½’çº³æ€»ç»“ï¼Œä¸ºæšä¸¾æ•°æ®ï¼šå¯¹äº§å“çš„çœ‹æ³•ï¼Œå¯¹è¥é”€æ‰‹æ®µçš„è¯„è®ºï¼Œè¡¨è¾¾å‘å¾€ï¼Œè¡¨è¾¾è®½åˆºï¼Œå…¶ä»–ã€‚

è¯·éµå¾ªä»¥ä¸‹åŸåˆ™è¿›è¡Œä¿¡æ¯æå–ï¼š

- ç†è§£æ¯ä¸ªè¯„è®ºçš„å†…å®¹ï¼Œç¡®ä¿æå–çš„ä¿¡æ¯å‡†ç¡®ã€‚
- æ— è®ºåŸæ–‡æ˜¯ä»€ä¹ˆè¯­è¨€ï¼Œè¯·ä½¿ç”¨ä¸­æ–‡è¾“å‡ºæå–ç»“æœã€‚
- æ¯æ¡è¯„è®ºéƒ½å¸¦æœ‰ idï¼Œåœ¨è¿”å›æ€»ç»“æ—¶éœ€è¦æä¾›å¯¹åº”çš„ idï¼Œå¦‚æœè¯„è®ºä¸­ä¸å« idï¼Œåˆ™ä¸éœ€è¦åˆ†æã€‚
- è¯·å¿½ç•¥è¯„è®ºæ–‡æœ¬ä¸­çš„ä¸å¿…è¦ç©ºæ ¼å’Œæ¢è¡Œç¬¦ã€‚'''
        self.get_info_suffix = '''å¦‚æœè¯„è®ºæ–‡æœ¬ä¸­åŒ…å«ç›¸å…³ä¿¡æ¯ï¼Œè¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºæå–çš„ä¿¡æ¯ï¼š
[{"id":"æä¾›çš„ id","sentiment": "æƒ…æ„Ÿå€¾å‘", "topic": "ä¸»è¦ä¸»é¢˜", "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", ...], "summary": "å¯¹äº§å“çš„çœ‹æ³•|å¯¹è¥é”€æ‰‹æ®µçš„è¯„è®º|è¡¨è¾¾å‘å¾€|è¡¨è¾¾è®½åˆº|å…¶ä»–ã€‚"}]

ç¤ºä¾‹ï¼š
[{"id":"1234","sentiment": "æ­£é¢", "topic": "æœåŠ¡è´¨é‡", "keywords": ["å‹å¥½", "å¿«é€Ÿ"], "summary": "è¡¨è¾¾å‘å¾€"}, {"id":"1235","sentiment": "è´Ÿé¢", "topic": "äº§å“è´¨é‡", "keywords": ["ç ´æŸ"], "summary": "è¡¨è¾¾è®½åˆº"}]
å¦‚æœè¯„è®ºæ–‡æœ¬ä¸­ä¸åŒ…å«ä»»ä½•ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¾“å‡ºï¼š[]ã€‚'''

    async def get_anlalysis_res(self, text: str) -> list[dict]:
        if not text:
            return []
        content = f'<text>\n{text}\n</text>\n\n{self.get_info_suffix}'
        result = await llm([{'role': 'system', 'content': self.get_info_prompt}, {'role': 'user', 'content': content}],
                           model=self.model, temperature=0.1, response_format={"type": "json_object"})
        self.logger.debug(f'get_info llm output:\n{result}')
        if not result:
            return []
        # result = json_repair.repair_json(result, return_objects=True)
        print("get analysis result" + result)
        if not isinstance(result, list):
            self.logger.warning("failed to parse from llm output")
            return []
        if not result:
            self.logger.debug("no info found")
            return []
        # ä¸šåŠ¡æ•°æ®æ¸…æ´—
        return result

    async def __call__(self, text: str, link_dict: dict, base_url: str, author: str = None, publish_date: str = None) -> \
            tuple[list, set, str, str]:
        if not author and not publish_date and text:
            author, publish_date = await self.get_author_and_publish_date(text)

        if not author or author.lower() == 'na':
            author = urlparse(base_url).netloc

        if not publish_date or publish_date.lower() == 'na':
            publish_date = datetime.now().strftime('%Y-%m-%d')

        related_urls = await self.get_more_related_urls(link_dict, base_url)

        info_prefix = f"//{author} {publish_date}//"
        lines = text.split('\n')
        text = ''
        infos = []
        for line in lines:
            text = f'{text}{line}'
            if len(text) > 2048:
                cache = await self.get_info(text, info_prefix, link_dict)
                infos.extend(cache)
                text = ''
        if text:
            cache = await self.get_info(text, info_prefix, link_dict)
            infos.extend(cache)

        return infos, related_urls, author, publish_date


if __name__ == '__main__':
    comment = """
[{
    "id": 112,
    "content": "Yesss youâ€™re doing this so right"
  },
  {
    "id": 122,
    "content": "ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ’ğŸ’"
  },
  {
    "id": 345,
    "content": "Write a book about family vlogging it would be a best seller"
  },
  {
    "id": 423,
    "content": "Stop. If this isnâ€™t the cutest thing Iâ€™ve ever seenğŸ¥¹ğŸ¥¹ğŸ˜ğŸ’•"
  },
  {
    "id": 5,
    "content": "this is so cuteeeee"
  },
  {
    "id": 6,
    "content": "Beautiful â¤ï¸"
  },
  {
    "id": 7,
    "content": "â¤ï¸â¤ï¸â¤ï¸"
  },
  {
    "id": 8,
    "content": "This is so sweetğŸ˜"
  },
  {
    "id": 9,
    "content": "Beautiful ring given by beautiful personğŸ˜"
  },
  {
    "id": 10,
    "content": "I would of been upset lol"
  },
  {
    "id": 11,
    "content": "Congrats! ğŸ¾"
  },
  {
    "id": 12,
    "content": "â¤ï¸ğŸ¥¹ğŸ˜­"
  },
  {
    "id": 13,
    "content": "it so bad"
  },
  {
    "id": 16,
    "content": "Every move he does is for $ his true colours are showing ..Everyone over looked his trips to Florida to party while the mother of his kids was home running the businesses & taking care of the kids ..He quit his job when his 1st was a new born ..couldnâ€™t even do his YT channel ..Just spent. The $ his kids madeâ€¦Idk any women who wouldnâ€™t want to go find another partner who wants to be an adult work build a real future not just play all day ..Thank god ppl@are taking the rose colour glasses off to see why she fell in love with someone who wanted the same life she did."
  }
  ]
"""


    async def main():
        project_dir = os.environ.get("PROJECT_DIR", "/Users/yohong/code/yohong/wiseflow")
        wiseflow_logger = get_logger('general_process', project_dir)
        gie = GeneralAnalysisInfoExtractor(wiseflow_logger)
        # comment_list = json.loads(comment)

        # æ¯ 10 ä¸ª comment æ‹¼æ¥ä¸º str ç„¶åè°ƒç”¨ä¸€æ¬¡æ¥å£
        # comments = '\n'.join([c['content'] for c in comment_list])
        results = []
        res = await gie.get_anlalysis_res(comment)
        results.extend(res)
        print(res)


    asyncio.run(main())
